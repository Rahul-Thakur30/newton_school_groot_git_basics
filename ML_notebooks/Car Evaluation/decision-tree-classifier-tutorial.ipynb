{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"0\"></a>\n",
    "# **Decision Tree Classifier Tutorial with Python**\n",
    "\n",
    "\n",
    "\n",
    "In this kernel, I build a Decision Tree Classifier to predict the safety of the car. I build two models, one with criterion `gini index` and another one with criterion `entropy`. I implement Decision Tree Classification with Python and Scikit-Learn. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"0.1\"></a>\n",
    "# **Table of Contents**\n",
    "\n",
    "\n",
    "1.\t[Introduction to Decision Tree algorithm](#1)\n",
    "2.\t[Classification and Regression Trees](#2)\n",
    "3.\t[Decision Tree algorithm terminology](#3)\n",
    "4.\t[Decision Tree algorithm intuition](#4)\n",
    "5.\t[Attribute selection measures](#5)\n",
    "    - 5.1 [Information gain](#5.1)\n",
    "    - 5.2 [Gini index](#5.2)\n",
    "6.\t[Overfitting in Decision-Tree algorithm](#6)\n",
    "7.\t[Import libraries](#7)\n",
    "8.\t[Import dataset](#8)\n",
    "9.\t[Exploratory data analysis](#9)\n",
    "10.\t[Declare feature vector and target variable](#10)\n",
    "11.\t[Split data into separate training and test set](#11)\n",
    "12.\t[Feature engineering](#12)\n",
    "13.\t[Decision Tree classifier with criterion gini-index](#13)\n",
    "14.\t[Decision Tree classifier with criterion entropy](#14)\n",
    "15.\t[Confusion matrix](#15)\n",
    "16.\t[Classification report](#16)\n",
    "17.\t[Results and conclusion](#17)\n",
    "18. [References](#18)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **1. Introduction to Decision Tree algorithm** <a class=\"anchor\" id=\"1\"></a>\n",
    "\n",
    "[Table of Contents](#0.1)\n",
    "\n",
    "A Decision Tree algorithm is one of the most popular machine learning algorithms. It uses a tree like structure and their possible combinations to solve a particular problem. It belongs to the class of supervised learning algorithms where it can be used for both classification and regression purposes. \n",
    "\n",
    "\n",
    "A decision tree is a structure that includes a root node, branches, and leaf nodes. Each internal node denotes a test on an attribute, each branch denotes the outcome of a test, and each leaf node holds a class label. The topmost node in the tree is the root node. \n",
    "\n",
    "\n",
    "We make some assumptions while implementing the Decision-Tree algorithm. These are listed below:-\n",
    "\n",
    "1. At the beginning, the whole training set is considered as the root.\n",
    "2. Feature values need to be categorical. If the values are continuous then they are discretized prior to building the model.\n",
    "3. Records are distributed recursively on the basis of attribute values.\n",
    "4. Order to placing attributes as root or internal node of the tree is done by using some statistical approach.\n",
    "\n",
    "\n",
    "I will describe Decision Tree terminology in later section.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **2. Classification and Regression Trees (CART)** <a class=\"anchor\" id=\"2\"></a>\n",
    "\n",
    "[Table of Contents](#0.1)\n",
    "\n",
    "\n",
    "Nowadays, Decision Tree algorithm is known by its modern name **CART** which stands for **Classification and Regression Trees**. Classification and Regression Trees or **CART** is a term introduced by Leo Breiman to refer to Decision Tree algorithms that can be used for classification and regression modeling problems.\n",
    "\n",
    "\n",
    "The CART algorithm provides a foundation for other important algorithms like bagged decision trees, random forest and boosted decision trees. In this kernel, I will solve a classification problem. So, I will refer the algorithm also as Decision Tree Classification problem. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **3. Decision Tree algorithm terminology** <a class=\"anchor\" id=\"3\"></a>\n",
    "\n",
    "[Table of Contents](#0.1)\n",
    "\n",
    "\n",
    "- In a Decision Tree algorithm, there is a tree like structure in which each internal node represents a test on an attribute, each branch represents the outcome of the test, and each leaf node represents a class label. The paths from the root node to leaf node represent classification rules.\n",
    "\n",
    "- We can see that there is some terminology involved in Decision Tree algorithm. The terms involved in Decision Tree algorithm are as follows:-\n",
    "\n",
    "\n",
    "## **Root Node**\n",
    "\n",
    "- It represents the entire population or sample. This further gets divided into two or more homogeneous sets.\n",
    "\n",
    "\n",
    "## **Splitting**\n",
    "\n",
    "- It is a process of dividing a node into two or more sub-nodes.\n",
    "\n",
    "\n",
    "## Decision Node\n",
    "\n",
    "- When a sub-node splits into further sub-nodes, then it is called a decision node.\n",
    "\n",
    "\n",
    "## Leaf/Terminal Node\n",
    "\n",
    "- Nodes that do not split are called Leaf or Terminal nodes.\n",
    "\n",
    "\n",
    "## Pruning\n",
    "\n",
    "- When we remove sub-nodes of a decision node, this process is called pruning. It is the opposite process of splitting.\n",
    "\n",
    "\n",
    "## Branch/Sub-Tree\n",
    "\n",
    "- A sub-section of an entire tree is called a branch or sub-tree.\n",
    "\n",
    "\n",
    "## Parent and Child Node\n",
    "\n",
    "- A node, which is divided into sub-nodes is called the parent node of sub-nodes where sub-nodes are the children of a parent node. \n",
    "\n",
    "\n",
    "The above terminology is represented clearly in the following diagram:-"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **4. Decision Tree algorithm intuition** <a class=\"anchor\" id=\"4\"></a>\n",
    "\n",
    "[Table of Contents](#0.1)\n",
    "\n",
    "The Decision-Tree algorithm is one of the most frequently and widely used supervised machine learning algorithms that can be used for both classification and regression tasks. The intuition behind the Decision-Tree algorithm is very simple to understand.\n",
    "\n",
    "\n",
    "The Decision Tree algorithm intuition is as follows:-\n",
    "\n",
    "\n",
    "1.\tFor each attribute in the dataset, the Decision-Tree algorithm forms a node. The most important attribute is placed at the root node. \n",
    "\n",
    "2.\tFor evaluating the task in hand, we start at the root node and we work our way down the tree by following the corresponding node that meets our condition or decision.\n",
    "\n",
    "3.\tThis process continues until a leaf node is reached. It contains the prediction or the outcome of the Decision Tree.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **5. Attribute selection measures** <a class=\"anchor\" id=\"5\"></a>\n",
    "\n",
    "[Table of Contents](#0.1)\n",
    "\n",
    "\n",
    "The primary challenge in the Decision Tree implementation is to identify the attributes which we consider as the root node and each level. This process is known as the **attributes selection**. There are different attributes selection measure to identify the attribute which can be considered as the root node at each level.\n",
    "\n",
    "\n",
    "There are 2 popular attribute selection measures. They are as follows:-\n",
    "\n",
    "\n",
    "- **Information gain**\n",
    "\n",
    "- **Gini index**\n",
    "\n",
    "\n",
    "While using **Information gain** as a criterion, we assume attributes to be categorical and for **Gini index** attributes are assumed to be continuous. These attribute selection measures are described below.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **5.1 Information gain** <a class=\"anchor\" id=\"5.1\"></a>\n",
    "\n",
    "[Table of Contents](#0.1)\n",
    "\n",
    "\n",
    "By using information gain as a criterion, we try to estimate the information contained by each attribute. To understand the concept of Information Gain, we need to know another concept called **Entropy**. \n",
    "\n",
    "## **Entropy**\n",
    "\n",
    "Entropy measures the impurity in the given dataset. In Physics and Mathematics, entropy is referred to as the randomness or uncertainty of a random variable X. In information theory, it refers to the impurity in a group of examples. **Information gain** is the decrease in entropy. Information gain computes the difference between entropy before split and average entropy after split of the dataset based on given attribute values. \n",
    "\n",
    "Entropy is represented by the following formula:-\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Entropy](http://www.learnbymarketing.com/wp-content/uploads/2016/02/entropy-formula.png)\n",
    "\n",
    "\n",
    "\n",
    "Here, **c** is the number of classes and **pi** is the probability associated with the ith class. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ID3 (Iterative Dichotomiser) Decision Tree algorithm uses entropy to calculate information gain. So, by calculating decrease in **entropy measure** of each attribute we can calculate their information gain. The attribute with the highest information gain is chosen as the splitting attribute at the node."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **5.2 Gini index** <a class=\"anchor\" id=\"5.2\"></a>\n",
    "\n",
    "[Table of Contents](#0.1)\n",
    "\n",
    "\n",
    "Another attribute selection measure that **CART (Categorical and Regression Trees)** uses is the **Gini index**. It uses the Gini method to create split points. \n",
    "\n",
    "\n",
    "Gini index can be represented with the following diagram:-"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Gini index**\n",
    "\n",
    "![Gini index](https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcRzYHkcmZKKp2sJN1HpHvw-NgqbD9EnapnbXozXRgajrSGvEnYy&s)\n",
    "\n",
    "\n",
    "Here, again **c** is the number of classes and **pi** is the probability associated with the ith class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gini index says, if we randomly select two items from a population, they must be of the same class and probability for this is 1 if the population is pure.\n",
    "\n",
    "It works with the categorical target variable “Success” or “Failure”. It performs only binary splits. The higher the value of Gini, higher the homogeneity. CART (Classification and Regression Tree) uses the Gini method to create binary splits.\n",
    "\n",
    "Steps to Calculate Gini for a split\n",
    "\n",
    "1.\tCalculate Gini for sub-nodes, using formula sum of the square of probability for success and failure (p^2+q^2).\n",
    "\n",
    "2.\tCalculate Gini for split using weighted Gini score of each node of that split.\n",
    "\n",
    "\n",
    "In case of a discrete-valued attribute, the subset that gives the minimum gini index for that chosen is selected as a splitting attribute. In the case of continuous-valued attributes, the strategy is to select each pair of adjacent values as a possible split-point and point with smaller gini index chosen as the splitting point. The attribute with minimum Gini index is chosen as the splitting attribute."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **6. Overfitting in Decision Tree algorithm** <a class=\"anchor\" id=\"6\"></a>\n",
    "\n",
    "[Table of Contents](#0.1)\n",
    "\n",
    "\n",
    "Overfitting is a practical problem while building a Decision-Tree model. The problem of overfitting is considered when the algorithm continues to go deeper and deeper to reduce the training-set error but results with an increased test-set error. So, accuracy of prediction for our model goes down. It generally happens when we build many branches due to outliers and irregularities in data.\n",
    "\n",
    "Two approaches which can be used to avoid overfitting are as follows:-\n",
    "\n",
    "- Pre-Pruning\n",
    "\n",
    "- Post-Pruning\n",
    "\n",
    "\n",
    "## **Pre-Pruning**\n",
    "\n",
    "In pre-pruning, we stop the tree construction a bit early. We prefer not to split a node if its goodness measure is below a threshold value. But it is difficult to choose an appropriate stopping point.\n",
    "\n",
    "\n",
    "## **Post-Pruning**\n",
    "\n",
    "In post-pruning, we go deeper and deeper in the tree to build a complete tree. If the tree shows the overfitting problem then pruning is done as a post-pruning step. We use the cross-validation data to check the effect of our pruning. Using cross-validation data, we test whether expanding a node will result in improve or not. If it shows an improvement, then we can continue by expanding that node. But if it shows a reduction in accuracy then it should not be expanded. So, the node should be converted to a leaf node."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **7. Import libraries** <a class=\"anchor\" id=\"7\"></a>\n",
    "\n",
    "[Table of Contents](#0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt # data visualization\n",
    "import seaborn as sns # statistical data visualization\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **8. Import dataset** <a class=\"anchor\" id=\"8\"></a>\n",
    "\n",
    "[Table of Contents](#0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = 'csv/car_evaluation.csv'\n",
    "\n",
    "df = pd.read_csv(data, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>low</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>med</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>high</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>med</td>\n",
       "      <td>low</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>med</td>\n",
       "      <td>med</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0      1  2  3      4     5      6\n",
       "0  vhigh  vhigh  2  2  small   low  unacc\n",
       "1  vhigh  vhigh  2  2  small   med  unacc\n",
       "2  vhigh  vhigh  2  2  small  high  unacc\n",
       "3  vhigh  vhigh  2  2    med   low  unacc\n",
       "4  vhigh  vhigh  2  2    med   med  unacc"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **9. Exploratory data analysis** <a class=\"anchor\" id=\"9\"></a>\n",
    "\n",
    "[Table of Contents](#0.1)\n",
    "\n",
    "\n",
    "Now, I will explore the data to gain insights about the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1728, 7)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view dimensions of dataset\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that there are 1728 instances and 7 variables in the data set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View top 5 rows of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>low</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>med</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>high</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>med</td>\n",
       "      <td>low</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>med</td>\n",
       "      <td>med</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0      1  2  3      4     5      6\n",
       "0  vhigh  vhigh  2  2  small   low  unacc\n",
       "1  vhigh  vhigh  2  2  small   med  unacc\n",
       "2  vhigh  vhigh  2  2  small  high  unacc\n",
       "3  vhigh  vhigh  2  2    med   low  unacc\n",
       "4  vhigh  vhigh  2  2    med   med  unacc"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# preview the dataset\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rename column names\n",
    "\n",
    "We can see that the dataset does not have proper column names. The columns are merely labelled as 0,1,2.... and so on. We should give proper names to the columns. I will do it as follows:-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['buying', 'maint', 'doors', 'persons', 'lug_boot', 'safety', 'class']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_names = ['buying', 'maint', 'doors', 'persons', 'lug_boot', 'safety', 'class']\n",
    "\n",
    "\n",
    "df.columns = col_names\n",
    "\n",
    "col_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>buying</th>\n",
       "      <th>maint</th>\n",
       "      <th>doors</th>\n",
       "      <th>persons</th>\n",
       "      <th>lug_boot</th>\n",
       "      <th>safety</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>low</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>med</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>high</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>med</td>\n",
       "      <td>low</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>med</td>\n",
       "      <td>med</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  buying  maint doors persons lug_boot safety  class\n",
       "0  vhigh  vhigh     2       2    small    low  unacc\n",
       "1  vhigh  vhigh     2       2    small    med  unacc\n",
       "2  vhigh  vhigh     2       2    small   high  unacc\n",
       "3  vhigh  vhigh     2       2      med    low  unacc\n",
       "4  vhigh  vhigh     2       2      med    med  unacc"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's again preview the dataset\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the column names are renamed. Now, the columns have meaningful names."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View summary of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1728 entries, 0 to 1727\n",
      "Data columns (total 7 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   buying    1728 non-null   object\n",
      " 1   maint     1728 non-null   object\n",
      " 2   doors     1728 non-null   object\n",
      " 3   persons   1728 non-null   object\n",
      " 4   lug_boot  1728 non-null   object\n",
      " 5   safety    1728 non-null   object\n",
      " 6   class     1728 non-null   object\n",
      "dtypes: object(7)\n",
      "memory usage: 94.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequency distribution of values in variables\n",
    "\n",
    "Now, I will check the frequency counts of categorical variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "col_name: buying\n",
      "vhigh    432\n",
      "high     432\n",
      "med      432\n",
      "low      432\n",
      "Name: buying, dtype: int64\n",
      "col_name: maint\n",
      "vhigh    432\n",
      "high     432\n",
      "med      432\n",
      "low      432\n",
      "Name: maint, dtype: int64\n",
      "col_name: doors\n",
      "2        432\n",
      "3        432\n",
      "4        432\n",
      "5more    432\n",
      "Name: doors, dtype: int64\n",
      "col_name: persons\n",
      "2       576\n",
      "4       576\n",
      "more    576\n",
      "Name: persons, dtype: int64\n",
      "col_name: lug_boot\n",
      "small    576\n",
      "med      576\n",
      "big      576\n",
      "Name: lug_boot, dtype: int64\n",
      "col_name: safety\n",
      "low     576\n",
      "med     576\n",
      "high    576\n",
      "Name: safety, dtype: int64\n",
      "col_name: class\n",
      "unacc    1210\n",
      "acc       384\n",
      "good       69\n",
      "vgood      65\n",
      "Name: class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "col_names = ['buying', 'maint', 'doors', 'persons', 'lug_boot', 'safety', 'class']\n",
    "\n",
    "\n",
    "for col in col_names:\n",
    "    print(\"col_name:\",col)\n",
    "    print(df[col].value_counts())   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the `doors` and `persons` are categorical in nature. So, I will treat them as categorical variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary of variables\n",
    "\n",
    "\n",
    "- There are 7 variables in the dataset. All the variables are of categorical data type.\n",
    "\n",
    "\n",
    "- These are given by `buying`, `maint`, `doors`, `persons`, `lug_boot`, `safety` and `class`.\n",
    "\n",
    "\n",
    "- `class` is the target variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore `class` variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "unacc    1210\n",
       "acc       384\n",
       "good       69\n",
       "vgood      65\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['class'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `class` target variable is ordinal in nature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing values in variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "buying      0\n",
       "maint       0\n",
       "doors       0\n",
       "persons     0\n",
       "lug_boot    0\n",
       "safety      0\n",
       "class       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check missing values in variables\n",
    "\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that there are no missing values in the dataset. I have checked the frequency distribution of values previously. It also confirms that there are no missing values in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **10. Declare feature vector and target variable** <a class=\"anchor\" id=\"10\"></a>\n",
    "\n",
    "[Table of Contents](#0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['class'], axis=1)\n",
    "\n",
    "y = df['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>buying</th>\n",
       "      <th>maint</th>\n",
       "      <th>doors</th>\n",
       "      <th>persons</th>\n",
       "      <th>lug_boot</th>\n",
       "      <th>safety</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>med</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>med</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>med</td>\n",
       "      <td>med</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  buying  maint doors persons lug_boot safety\n",
       "0  vhigh  vhigh     2       2    small    low\n",
       "1  vhigh  vhigh     2       2    small    med\n",
       "2  vhigh  vhigh     2       2    small   high\n",
       "3  vhigh  vhigh     2       2      med    low\n",
       "4  vhigh  vhigh     2       2      med    med"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       unacc\n",
       "1       unacc\n",
       "2       unacc\n",
       "3       unacc\n",
       "4       unacc\n",
       "        ...  \n",
       "1723     good\n",
       "1724    vgood\n",
       "1725    unacc\n",
       "1726     good\n",
       "1727    vgood\n",
       "Name: class, Length: 1728, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **11. Split data into separate training and test set** <a class=\"anchor\" id=\"11\"></a>\n",
    "\n",
    "[Table of Contents](#0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split X and y into training and testing sets\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.33, random_state =1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1157, 6), (571, 6))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the shape of X_train and X_test\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **12. Feature Engineering** <a class=\"anchor\" id=\"12\"></a>\n",
    "\n",
    "[Table of Contents](#0.1)\n",
    "\n",
    "\n",
    "**Feature Engineering** is the process of transforming raw data into useful features that help us to understand our model better and increase its predictive power. I will carry out feature engineering on different types of variables.\n",
    "\n",
    "\n",
    "First, I will check the data types of variables again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "buying      object\n",
       "maint       object\n",
       "doors       object\n",
       "persons     object\n",
       "lug_boot    object\n",
       "safety      object\n",
       "dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check data types in X_train\n",
    "\n",
    "X_train.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode categorical variables\n",
    "\n",
    "\n",
    "Now, I will encode the categorical variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>buying</th>\n",
       "      <th>maint</th>\n",
       "      <th>doors</th>\n",
       "      <th>persons</th>\n",
       "      <th>lug_boot</th>\n",
       "      <th>safety</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1611</th>\n",
       "      <td>low</td>\n",
       "      <td>med</td>\n",
       "      <td>5more</td>\n",
       "      <td>more</td>\n",
       "      <td>small</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1177</th>\n",
       "      <td>med</td>\n",
       "      <td>med</td>\n",
       "      <td>5more</td>\n",
       "      <td>4</td>\n",
       "      <td>big</td>\n",
       "      <td>med</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>med</td>\n",
       "      <td>2</td>\n",
       "      <td>more</td>\n",
       "      <td>med</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>low</td>\n",
       "      <td>2</td>\n",
       "      <td>more</td>\n",
       "      <td>big</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>921</th>\n",
       "      <td>med</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>med</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     buying  maint  doors persons lug_boot safety\n",
       "1611    low    med  5more    more    small    low\n",
       "1177    med    med  5more       4      big    med\n",
       "239   vhigh    med      2    more      med   high\n",
       "350   vhigh    low      2    more      big   high\n",
       "921     med  vhigh      4       2      med    low"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: category_encoders in c:\\users\\rahul\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (2.5.1.post0)\n",
      "Requirement already satisfied: patsy>=0.5.1 in c:\\users\\rahul\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from category_encoders) (0.5.3)\n",
      "Requirement already satisfied: statsmodels>=0.9.0 in c:\\users\\rahul\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from category_encoders) (0.13.5)\n",
      "Requirement already satisfied: numpy>=1.14.0 in c:\\users\\rahul\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from category_encoders) (1.23.3)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in c:\\users\\rahul\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from category_encoders) (1.1.2)\n",
      "Requirement already satisfied: scipy>=1.0.0 in c:\\users\\rahul\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from category_encoders) (1.9.1)\n",
      "Requirement already satisfied: pandas>=1.0.5 in c:\\users\\rahul\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from category_encoders) (1.4.4)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\rahul\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas>=1.0.5->category_encoders) (2022.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\rahul\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas>=1.0.5->category_encoders) (2.8.2)\n",
      "Requirement already satisfied: six in c:\\users\\rahul\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from patsy>=0.5.1->category_encoders) (1.16.0)\n",
      "Requirement already satisfied: joblib>=1.0.0 in c:\\users\\rahul\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn>=0.20.0->category_encoders) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\rahul\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn>=0.20.0->category_encoders) (3.1.0)\n",
      "Requirement already satisfied: packaging>=21.3 in c:\\users\\rahul\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from statsmodels>=0.9.0->category_encoders) (21.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\rahul\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from packaging>=21.3->statsmodels>=0.9.0->category_encoders) (3.0.9)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.2.2 -> 22.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install category_encoders\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that all  the variables are ordinal categorical data type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import category encoders\n",
    "\n",
    "import category_encoders as ce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode variables with ordinal encoding\n",
    "\n",
    "encoder = ce.OrdinalEncoder(cols=['buying', 'maint', 'doors', 'persons', 'lug_boot', 'safety'])\n",
    "\n",
    "\n",
    "X_train = encoder.fit_transform(X_train)\n",
    "\n",
    "X_test = encoder.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>buying</th>\n",
       "      <th>maint</th>\n",
       "      <th>doors</th>\n",
       "      <th>persons</th>\n",
       "      <th>lug_boot</th>\n",
       "      <th>safety</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1611</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1177</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>921</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      buying  maint  doors  persons  lug_boot  safety\n",
       "1611       1      1      1        1         1       1\n",
       "1177       2      1      1        2         2       2\n",
       "239        3      1      2        1         3       3\n",
       "350        3      2      2        1         2       3\n",
       "921        2      3      3        3         3       1"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>buying</th>\n",
       "      <th>maint</th>\n",
       "      <th>doors</th>\n",
       "      <th>persons</th>\n",
       "      <th>lug_boot</th>\n",
       "      <th>safety</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1233</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>592</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>625</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1546</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>730</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      buying  maint  doors  persons  lug_boot  safety\n",
       "1233       2      2      4        1         1       1\n",
       "592        4      4      4        1         2       2\n",
       "625        4      4      1        3         3       2\n",
       "1546       1      1      4        3         2       2\n",
       "730        4      1      1        3         1       2"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have training and test set ready for model building. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **13. Decision Tree Classifier with criterion gini index** <a class=\"anchor\" id=\"13\"></a>\n",
    "\n",
    "[Table of Contents](#0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier(max_depth=7, random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(max_depth=7, random_state=0)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier(max_depth=7, random_state=0)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# instantiate the DecisionTreeClassifier model with criterion gini index\n",
    "\n",
    "clf_gini = DecisionTreeClassifier(criterion='gini', max_depth=7, random_state=0)\n",
    "\n",
    "\n",
    "# fit the model\n",
    "clf_gini.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict the Test set results with criterion gini index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_gini = clf_gini.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check accuracy score with criterion gini index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy score with criterion gini index: 0.9107\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score,precision_score,recall_score\n",
    "\n",
    "print('Model accuracy score with criterion gini index: {0:0.4f}'. format(accuracy_score(y_test, y_pred_gini)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, **y_test** are the true class labels and **y_pred_gini** are the predicted class labels in the test-set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare the train-set and test-set accuracy\n",
    "\n",
    "\n",
    "Now, I will compare the train-set and test-set accuracy to check for overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['unacc', 'acc', 'acc', ..., 'acc', 'unacc', 'unacc'], dtype=object)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_train_gini = clf_gini.predict(X_train)\n",
    "\n",
    "y_pred_train_gini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training-set accuracy score: 0.9430\n"
     ]
    }
   ],
   "source": [
    "print('Training-set accuracy score: {0:0.4f}'. format(accuracy_score(y_train, y_pred_train_gini)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for overfitting and underfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.9430\n",
      "Test set score: 0.9107\n"
     ]
    }
   ],
   "source": [
    "# print the scores on training and test set\n",
    "\n",
    "print('Training set score: {:.4f}'.format(clf_gini.score(X_train, y_train)))\n",
    "\n",
    "print('Test set score: {:.4f}'.format(clf_gini.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, the training-set accuracy score is 0.7865 while the test-set accuracy to be 0.8021. These two values are quite comparable. So, there is no sign of overfitting. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize decision-trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Text(0.5978260869565217, 0.9375, 'X[3] <= 2.5\\ngini = 0.459\\nsamples = 1157\\nvalue = [262, 44, 807, 44]'),\n",
       " Text(0.5760869565217391, 0.8125, 'X[5] <= 1.5\\ngini = 0.579\\nsamples = 775\\nvalue = [262, 44, 425, 44]'),\n",
       " Text(0.5543478260869565, 0.6875, 'gini = 0.0\\nsamples = 249\\nvalue = [0, 0, 249, 0]'),\n",
       " Text(0.5978260869565217, 0.6875, 'X[0] <= 2.5\\ngini = 0.626\\nsamples = 526\\nvalue = [262, 44, 176, 44]'),\n",
       " Text(0.34782608695652173, 0.5625, 'X[1] <= 2.5\\ngini = 0.621\\nsamples = 265\\nvalue = [148, 44, 29, 44]'),\n",
       " Text(0.17391304347826086, 0.4375, 'X[5] <= 2.5\\ngini = 0.689\\nsamples = 125\\nvalue = [40, 44, 5, 36]'),\n",
       " Text(0.08695652173913043, 0.3125, 'X[4] <= 1.5\\ngini = 0.522\\nsamples = 62\\nvalue = [34, 26, 2, 0]'),\n",
       " Text(0.043478260869565216, 0.1875, 'X[0] <= 1.5\\ngini = 0.172\\nsamples = 21\\nvalue = [19, 0, 2, 0]'),\n",
       " Text(0.021739130434782608, 0.0625, 'gini = 0.0\\nsamples = 12\\nvalue = [12, 0, 0, 0]'),\n",
       " Text(0.06521739130434782, 0.0625, 'gini = 0.346\\nsamples = 9\\nvalue = [7, 0, 2, 0]'),\n",
       " Text(0.13043478260869565, 0.1875, 'X[0] <= 1.5\\ngini = 0.464\\nsamples = 41\\nvalue = [15, 26, 0, 0]'),\n",
       " Text(0.10869565217391304, 0.0625, 'gini = 0.236\\nsamples = 22\\nvalue = [3, 19, 0, 0]'),\n",
       " Text(0.15217391304347827, 0.0625, 'gini = 0.465\\nsamples = 19\\nvalue = [12, 7, 0, 0]'),\n",
       " Text(0.2608695652173913, 0.3125, 'X[4] <= 1.5\\ngini = 0.58\\nsamples = 63\\nvalue = [6, 18, 3, 36]'),\n",
       " Text(0.21739130434782608, 0.1875, 'X[0] <= 1.5\\ngini = 0.567\\nsamples = 17\\nvalue = [4, 10, 3, 0]'),\n",
       " Text(0.1956521739130435, 0.0625, 'gini = 0.346\\nsamples = 9\\nvalue = [0, 7, 2, 0]'),\n",
       " Text(0.2391304347826087, 0.0625, 'gini = 0.594\\nsamples = 8\\nvalue = [4, 3, 1, 0]'),\n",
       " Text(0.30434782608695654, 0.1875, 'X[4] <= 2.5\\ngini = 0.355\\nsamples = 46\\nvalue = [2, 8, 0, 36]'),\n",
       " Text(0.2826086956521739, 0.0625, 'gini = 0.0\\nsamples = 25\\nvalue = [0, 0, 0, 25]'),\n",
       " Text(0.32608695652173914, 0.0625, 'gini = 0.571\\nsamples = 21\\nvalue = [2, 8, 0, 11]'),\n",
       " Text(0.5217391304347826, 0.4375, 'X[4] <= 1.5\\ngini = 0.372\\nsamples = 140\\nvalue = [108, 0, 24, 8]'),\n",
       " Text(0.43478260869565216, 0.3125, 'X[5] <= 2.5\\ngini = 0.494\\nsamples = 47\\nvalue = [26, 0, 21, 0]'),\n",
       " Text(0.391304347826087, 0.1875, 'X[0] <= 1.5\\ngini = 0.33\\nsamples = 24\\nvalue = [5, 0, 19, 0]'),\n",
       " Text(0.3695652173913043, 0.0625, 'gini = 0.5\\nsamples = 10\\nvalue = [5, 0, 5, 0]'),\n",
       " Text(0.41304347826086957, 0.0625, 'gini = 0.0\\nsamples = 14\\nvalue = [0, 0, 14, 0]'),\n",
       " Text(0.4782608695652174, 0.1875, 'X[2] <= 2.5\\ngini = 0.159\\nsamples = 23\\nvalue = [21, 0, 2, 0]'),\n",
       " Text(0.45652173913043476, 0.0625, 'gini = 0.32\\nsamples = 10\\nvalue = [8, 0, 2, 0]'),\n",
       " Text(0.5, 0.0625, 'gini = 0.0\\nsamples = 13\\nvalue = [13, 0, 0, 0]'),\n",
       " Text(0.6086956521739131, 0.3125, 'X[1] <= 3.5\\ngini = 0.214\\nsamples = 93\\nvalue = [82, 0, 3, 8]'),\n",
       " Text(0.5652173913043478, 0.1875, 'X[5] <= 2.5\\ngini = 0.08\\nsamples = 48\\nvalue = [46, 0, 2, 0]'),\n",
       " Text(0.5434782608695652, 0.0625, 'gini = 0.165\\nsamples = 22\\nvalue = [20, 0, 2, 0]'),\n",
       " Text(0.5869565217391305, 0.0625, 'gini = 0.0\\nsamples = 26\\nvalue = [26, 0, 0, 0]'),\n",
       " Text(0.6521739130434783, 0.1875, 'X[0] <= 1.5\\ngini = 0.328\\nsamples = 45\\nvalue = [36, 0, 1, 8]'),\n",
       " Text(0.6304347826086957, 0.0625, 'gini = 0.472\\nsamples = 21\\nvalue = [13, 0, 0, 8]'),\n",
       " Text(0.6739130434782609, 0.0625, 'gini = 0.08\\nsamples = 24\\nvalue = [23, 0, 1, 0]'),\n",
       " Text(0.8478260869565217, 0.5625, 'X[1] <= 2.5\\ngini = 0.492\\nsamples = 261\\nvalue = [114, 0, 147, 0]'),\n",
       " Text(0.782608695652174, 0.4375, 'X[5] <= 2.5\\ngini = 0.41\\nsamples = 132\\nvalue = [94, 0, 38, 0]'),\n",
       " Text(0.717391304347826, 0.3125, 'X[4] <= 1.5\\ngini = 0.498\\nsamples = 66\\nvalue = [31, 0, 35, 0]'),\n",
       " Text(0.6956521739130435, 0.1875, 'gini = 0.0\\nsamples = 23\\nvalue = [0, 0, 23, 0]'),\n",
       " Text(0.7391304347826086, 0.1875, 'X[4] <= 2.5\\ngini = 0.402\\nsamples = 43\\nvalue = [31, 0, 12, 0]'),\n",
       " Text(0.717391304347826, 0.0625, 'gini = 0.0\\nsamples = 20\\nvalue = [20, 0, 0, 0]'),\n",
       " Text(0.7608695652173914, 0.0625, 'gini = 0.499\\nsamples = 23\\nvalue = [11, 0, 12, 0]'),\n",
       " Text(0.8478260869565217, 0.3125, 'X[4] <= 1.5\\ngini = 0.087\\nsamples = 66\\nvalue = [63, 0, 3, 0]'),\n",
       " Text(0.8260869565217391, 0.1875, 'X[2] <= 2.5\\ngini = 0.219\\nsamples = 24\\nvalue = [21, 0, 3, 0]'),\n",
       " Text(0.8043478260869565, 0.0625, 'gini = 0.42\\nsamples = 10\\nvalue = [7, 0, 3, 0]'),\n",
       " Text(0.8478260869565217, 0.0625, 'gini = 0.0\\nsamples = 14\\nvalue = [14, 0, 0, 0]'),\n",
       " Text(0.8695652173913043, 0.1875, 'gini = 0.0\\nsamples = 42\\nvalue = [42, 0, 0, 0]'),\n",
       " Text(0.9130434782608695, 0.4375, 'X[0] <= 3.5\\ngini = 0.262\\nsamples = 129\\nvalue = [20, 0, 109, 0]'),\n",
       " Text(0.8913043478260869, 0.3125, 'gini = 0.0\\nsamples = 67\\nvalue = [0, 0, 67, 0]'),\n",
       " Text(0.9347826086956522, 0.3125, 'X[1] <= 3.5\\ngini = 0.437\\nsamples = 62\\nvalue = [20, 0, 42, 0]'),\n",
       " Text(0.9130434782608695, 0.1875, 'gini = 0.0\\nsamples = 36\\nvalue = [0, 0, 36, 0]'),\n",
       " Text(0.9565217391304348, 0.1875, 'X[5] <= 2.5\\ngini = 0.355\\nsamples = 26\\nvalue = [20, 0, 6, 0]'),\n",
       " Text(0.9347826086956522, 0.0625, 'gini = 0.486\\nsamples = 12\\nvalue = [7, 0, 5, 0]'),\n",
       " Text(0.9782608695652174, 0.0625, 'gini = 0.133\\nsamples = 14\\nvalue = [13, 0, 1, 0]'),\n",
       " Text(0.6195652173913043, 0.8125, 'gini = 0.0\\nsamples = 382\\nvalue = [0, 0, 382, 0]')]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "\n",
    "from sklearn import tree\n",
    "\n",
    "tree.plot_tree(clf_gini.fit(X_train, y_train)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"PATH\"] += os.pathsep + 'C:\\Program Files\\Graphviz\\bin'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize decision-trees with graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3629\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3628\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3629\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3630\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\_libs\\index.pyx:136\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\_libs\\index.pyx:163\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:2131\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:2140\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 0",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[1;32mIn [45]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mgraphviz\u001b[39;00m \n\u001b[1;32m----> 2\u001b[0m dot_data \u001b[38;5;241m=\u001b[39m \u001b[43mtree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexport_graphviz\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclf_gini\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m                              \u001b[49m\u001b[43mfeature_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m                              \u001b[49m\u001b[43mclass_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m                              \u001b[49m\u001b[43mfilled\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrounded\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m                              \u001b[49m\u001b[43mspecial_characters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m graph \u001b[38;5;241m=\u001b[39m graphviz\u001b[38;5;241m.\u001b[39mSource(dot_data) \n\u001b[0;32m     10\u001b[0m graph\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\tree\\_export.py:889\u001b[0m, in \u001b[0;36mexport_graphviz\u001b[1;34m(decision_tree, out_file, max_depth, feature_names, class_names, label, filled, leaves_parallel, impurity, node_ids, proportion, rotate, rounded, special_characters, precision, fontname)\u001b[0m\n\u001b[0;32m    870\u001b[0m     out_file \u001b[38;5;241m=\u001b[39m StringIO()\n\u001b[0;32m    872\u001b[0m exporter \u001b[38;5;241m=\u001b[39m _DOTTreeExporter(\n\u001b[0;32m    873\u001b[0m     out_file\u001b[38;5;241m=\u001b[39mout_file,\n\u001b[0;32m    874\u001b[0m     max_depth\u001b[38;5;241m=\u001b[39mmax_depth,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    887\u001b[0m     fontname\u001b[38;5;241m=\u001b[39mfontname,\n\u001b[0;32m    888\u001b[0m )\n\u001b[1;32m--> 889\u001b[0m \u001b[43mexporter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexport\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdecision_tree\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    891\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_string:\n\u001b[0;32m    892\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m exporter\u001b[38;5;241m.\u001b[39mout_file\u001b[38;5;241m.\u001b[39mgetvalue()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\tree\\_export.py:462\u001b[0m, in \u001b[0;36m_DOTTreeExporter.export\u001b[1;34m(self, decision_tree)\u001b[0m\n\u001b[0;32m    460\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecurse(decision_tree, \u001b[38;5;241m0\u001b[39m, criterion\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimpurity\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    461\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 462\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecurse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdecision_tree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtree_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecision_tree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcriterion\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    464\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtail()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\tree\\_export.py:544\u001b[0m, in \u001b[0;36m_DOTTreeExporter.recurse\u001b[1;34m(self, tree, node_id, criterion, parent, depth)\u001b[0m\n\u001b[0;32m    541\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mout_file\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m ;\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    543\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m left_child \u001b[38;5;241m!=\u001b[39m _tree\u001b[38;5;241m.\u001b[39mTREE_LEAF:\n\u001b[1;32m--> 544\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecurse\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    545\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtree\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    546\u001b[0m \u001b[43m            \u001b[49m\u001b[43mleft_child\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    547\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    548\u001b[0m \u001b[43m            \u001b[49m\u001b[43mparent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnode_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    549\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdepth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdepth\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    550\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    551\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecurse(\n\u001b[0;32m    552\u001b[0m             tree,\n\u001b[0;32m    553\u001b[0m             right_child,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    556\u001b[0m             depth\u001b[38;5;241m=\u001b[39mdepth \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m    557\u001b[0m         )\n\u001b[0;32m    559\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\tree\\_export.py:551\u001b[0m, in \u001b[0;36m_DOTTreeExporter.recurse\u001b[1;34m(self, tree, node_id, criterion, parent, depth)\u001b[0m\n\u001b[0;32m    543\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m left_child \u001b[38;5;241m!=\u001b[39m _tree\u001b[38;5;241m.\u001b[39mTREE_LEAF:\n\u001b[0;32m    544\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecurse(\n\u001b[0;32m    545\u001b[0m             tree,\n\u001b[0;32m    546\u001b[0m             left_child,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    549\u001b[0m             depth\u001b[38;5;241m=\u001b[39mdepth \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m    550\u001b[0m         )\n\u001b[1;32m--> 551\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecurse\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    552\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtree\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    553\u001b[0m \u001b[43m            \u001b[49m\u001b[43mright_child\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    554\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    555\u001b[0m \u001b[43m            \u001b[49m\u001b[43mparent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnode_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    556\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdepth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdepth\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    557\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    559\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    560\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mranks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mleaves\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mstr\u001b[39m(node_id))\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\tree\\_export.py:521\u001b[0m, in \u001b[0;36m_DOTTreeExporter.recurse\u001b[1;34m(self, tree, node_id, criterion, parent, depth)\u001b[0m\n\u001b[0;32m    517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    518\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mranks[\u001b[38;5;28mstr\u001b[39m(depth)]\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mstr\u001b[39m(node_id))\n\u001b[0;32m    520\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mout_file\u001b[38;5;241m.\u001b[39mwrite(\n\u001b[1;32m--> 521\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m [label=\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (node_id, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnode_to_str\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtree\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    522\u001b[0m )\n\u001b[0;32m    524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilled:\n\u001b[0;32m    525\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mout_file\u001b[38;5;241m.\u001b[39mwrite(\n\u001b[0;32m    526\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, fillcolor=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_fill_color(tree, node_id)\n\u001b[0;32m    527\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\tree\\_export.py:367\u001b[0m, in \u001b[0;36m_BaseTreeExporter.node_to_str\u001b[1;34m(self, tree, node_id, criterion)\u001b[0m\n\u001b[0;32m    365\u001b[0m     node_string \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclass = \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    366\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclass_names \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 367\u001b[0m     class_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclass_names\u001b[49m\u001b[43m[\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m    368\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    369\u001b[0m     class_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (\n\u001b[0;32m    370\u001b[0m         characters[\u001b[38;5;241m1\u001b[39m],\n\u001b[0;32m    371\u001b[0m         np\u001b[38;5;241m.\u001b[39margmax(value),\n\u001b[0;32m    372\u001b[0m         characters[\u001b[38;5;241m2\u001b[39m],\n\u001b[0;32m    373\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\series.py:958\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    955\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[key]\n\u001b[0;32m    957\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m key_is_scalar:\n\u001b[1;32m--> 958\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    960\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_hashable(key):\n\u001b[0;32m    961\u001b[0m     \u001b[38;5;66;03m# Otherwise index.get_value will raise InvalidIndexError\u001b[39;00m\n\u001b[0;32m    962\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    963\u001b[0m         \u001b[38;5;66;03m# For labels that don't resolve as scalars like tuples and frozensets\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\series.py:1069\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[1;34m(self, label, takeable)\u001b[0m\n\u001b[0;32m   1066\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[label]\n\u001b[0;32m   1068\u001b[0m \u001b[38;5;66;03m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[1;32m-> 1069\u001b[0m loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1070\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39m_get_values_for_loc(\u001b[38;5;28mself\u001b[39m, loc, label)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3631\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3629\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3630\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m-> 3631\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3632\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3633\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3634\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3635\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3636\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "import graphviz \n",
    "dot_data = tree.export_graphviz(clf_gini, out_file=None, \n",
    "                              feature_names=X_train.columns,  \n",
    "                              class_names=y_train,  \n",
    "                              filled=True, rounded=True,  \n",
    "                              special_characters=True)\n",
    "\n",
    "graph = graphviz.Source(dot_data) \n",
    "\n",
    "graph "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **14. Decision Tree Classifier with criterion entropy** <a class=\"anchor\" id=\"14\"></a>\n",
    "\n",
    "[Table of Contents](#0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier(criterion=&#x27;entropy&#x27;, max_depth=3, random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(criterion=&#x27;entropy&#x27;, max_depth=3, random_state=0)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier(criterion='entropy', max_depth=3, random_state=0)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# instantiate the DecisionTreeClassifier model with criterion entropy\n",
    "\n",
    "clf_en = DecisionTreeClassifier(criterion='entropy', max_depth=3, random_state=0)\n",
    "\n",
    "\n",
    "# fit the model\n",
    "clf_en.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_para = {'criterion':['gini','entropy'],'max_depth':[4,5,6,7,8,9],\"min_samples_split\":[3,5,7]}\n",
    "from sklearn.model_selection import GridSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n",
      "[CV 1/5] END criterion=gini, max_depth=4, min_samples_split=3;, score=0.866 total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=4, min_samples_split=3;, score=0.836 total time=   0.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=4, min_samples_split=3;, score=0.857 total time=   0.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=4, min_samples_split=3;, score=0.848 total time=   0.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=4, min_samples_split=3;, score=0.835 total time=   0.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=4, min_samples_split=5;, score=0.866 total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=4, min_samples_split=5;, score=0.836 total time=   0.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=4, min_samples_split=5;, score=0.857 total time=   0.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=4, min_samples_split=5;, score=0.848 total time=   0.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=4, min_samples_split=5;, score=0.835 total time=   0.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=4, min_samples_split=7;, score=0.866 total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=4, min_samples_split=7;, score=0.836 total time=   0.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=4, min_samples_split=7;, score=0.857 total time=   0.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=4, min_samples_split=7;, score=0.848 total time=   0.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=4, min_samples_split=7;, score=0.835 total time=   0.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=5, min_samples_split=3;, score=0.888 total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=5, min_samples_split=3;, score=0.875 total time=   0.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=5, min_samples_split=3;, score=0.874 total time=   0.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=5, min_samples_split=3;, score=0.879 total time=   0.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=5, min_samples_split=3;, score=0.874 total time=   0.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=5, min_samples_split=5;, score=0.888 total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=5, min_samples_split=5;, score=0.875 total time=   0.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=5, min_samples_split=5;, score=0.874 total time=   0.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=5, min_samples_split=5;, score=0.879 total time=   0.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=5, min_samples_split=5;, score=0.874 total time=   0.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=5, min_samples_split=7;, score=0.888 total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=5, min_samples_split=7;, score=0.875 total time=   0.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=5, min_samples_split=7;, score=0.874 total time=   0.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=5, min_samples_split=7;, score=0.879 total time=   0.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=5, min_samples_split=7;, score=0.874 total time=   0.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=6, min_samples_split=3;, score=0.948 total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=6, min_samples_split=3;, score=0.914 total time=   0.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=6, min_samples_split=3;, score=0.939 total time=   0.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=6, min_samples_split=3;, score=0.961 total time=   0.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=6, min_samples_split=3;, score=0.922 total time=   0.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=6, min_samples_split=5;, score=0.948 total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=6, min_samples_split=5;, score=0.914 total time=   0.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=6, min_samples_split=5;, score=0.939 total time=   0.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=6, min_samples_split=5;, score=0.961 total time=   0.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=6, min_samples_split=5;, score=0.922 total time=   0.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=6, min_samples_split=7;, score=0.948 total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=6, min_samples_split=7;, score=0.914 total time=   0.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=6, min_samples_split=7;, score=0.939 total time=   0.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=6, min_samples_split=7;, score=0.961 total time=   0.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=6, min_samples_split=7;, score=0.922 total time=   0.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=7, min_samples_split=3;, score=0.944 total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=7, min_samples_split=3;, score=0.909 total time=   0.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=7, min_samples_split=3;, score=0.926 total time=   0.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=7, min_samples_split=3;, score=0.926 total time=   0.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=7, min_samples_split=3;, score=0.905 total time=   0.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=7, min_samples_split=5;, score=0.944 total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=7, min_samples_split=5;, score=0.909 total time=   0.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=7, min_samples_split=5;, score=0.926 total time=   0.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=7, min_samples_split=5;, score=0.926 total time=   0.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=7, min_samples_split=5;, score=0.905 total time=   0.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=7, min_samples_split=7;, score=0.944 total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=7, min_samples_split=7;, score=0.909 total time=   0.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=7, min_samples_split=7;, score=0.926 total time=   0.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=7, min_samples_split=7;, score=0.926 total time=   0.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=7, min_samples_split=7;, score=0.905 total time=   0.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=8, min_samples_split=3;, score=0.966 total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=8, min_samples_split=3;, score=0.953 total time=   0.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=8, min_samples_split=3;, score=0.961 total time=   0.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=8, min_samples_split=3;, score=0.974 total time=   0.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=8, min_samples_split=3;, score=0.952 total time=   0.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=8, min_samples_split=5;, score=0.966 total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=8, min_samples_split=5;, score=0.953 total time=   0.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=8, min_samples_split=5;, score=0.961 total time=   0.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=8, min_samples_split=5;, score=0.974 total time=   0.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=8, min_samples_split=5;, score=0.952 total time=   0.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=8, min_samples_split=7;, score=0.966 total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=8, min_samples_split=7;, score=0.948 total time=   0.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=8, min_samples_split=7;, score=0.948 total time=   0.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=8, min_samples_split=7;, score=0.957 total time=   0.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=8, min_samples_split=7;, score=0.939 total time=   0.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=9, min_samples_split=3;, score=0.953 total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=9, min_samples_split=3;, score=0.953 total time=   0.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=9, min_samples_split=3;, score=0.948 total time=   0.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=9, min_samples_split=3;, score=0.961 total time=   0.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=9, min_samples_split=3;, score=0.935 total time=   0.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=9, min_samples_split=5;, score=0.944 total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=9, min_samples_split=5;, score=0.944 total time=   0.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=9, min_samples_split=5;, score=0.952 total time=   0.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=9, min_samples_split=5;, score=0.974 total time=   0.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=9, min_samples_split=5;, score=0.931 total time=   0.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=9, min_samples_split=7;, score=0.940 total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=9, min_samples_split=7;, score=0.948 total time=   0.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=9, min_samples_split=7;, score=0.944 total time=   0.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=9, min_samples_split=7;, score=0.957 total time=   0.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=9, min_samples_split=7;, score=0.939 total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=4, min_samples_split=3;, score=0.866 total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=4, min_samples_split=3;, score=0.836 total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=4, min_samples_split=3;, score=0.857 total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=4, min_samples_split=3;, score=0.848 total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=4, min_samples_split=3;, score=0.835 total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=4, min_samples_split=5;, score=0.866 total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=4, min_samples_split=5;, score=0.836 total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=4, min_samples_split=5;, score=0.857 total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=4, min_samples_split=5;, score=0.848 total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=4, min_samples_split=5;, score=0.835 total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=4, min_samples_split=7;, score=0.866 total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=4, min_samples_split=7;, score=0.836 total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=4, min_samples_split=7;, score=0.857 total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=4, min_samples_split=7;, score=0.848 total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=4, min_samples_split=7;, score=0.835 total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=5, min_samples_split=3;, score=0.888 total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=5, min_samples_split=3;, score=0.875 total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=5, min_samples_split=3;, score=0.874 total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=5, min_samples_split=3;, score=0.879 total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=5, min_samples_split=3;, score=0.874 total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=5, min_samples_split=5;, score=0.888 total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=5, min_samples_split=5;, score=0.875 total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=5, min_samples_split=5;, score=0.874 total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=5, min_samples_split=5;, score=0.879 total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=5, min_samples_split=5;, score=0.874 total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=5, min_samples_split=7;, score=0.888 total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=5, min_samples_split=7;, score=0.875 total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=5, min_samples_split=7;, score=0.874 total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=5, min_samples_split=7;, score=0.879 total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=5, min_samples_split=7;, score=0.874 total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=6, min_samples_split=3;, score=0.948 total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=6, min_samples_split=3;, score=0.914 total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=6, min_samples_split=3;, score=0.939 total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=6, min_samples_split=3;, score=0.961 total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=6, min_samples_split=3;, score=0.922 total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=6, min_samples_split=5;, score=0.948 total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=6, min_samples_split=5;, score=0.914 total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=6, min_samples_split=5;, score=0.939 total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=6, min_samples_split=5;, score=0.961 total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=6, min_samples_split=5;, score=0.922 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END criterion=entropy, max_depth=6, min_samples_split=7;, score=0.948 total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=6, min_samples_split=7;, score=0.914 total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=6, min_samples_split=7;, score=0.939 total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=6, min_samples_split=7;, score=0.961 total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=6, min_samples_split=7;, score=0.922 total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=7, min_samples_split=3;, score=0.948 total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=7, min_samples_split=3;, score=0.909 total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=7, min_samples_split=3;, score=0.926 total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=7, min_samples_split=3;, score=0.918 total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=7, min_samples_split=3;, score=0.905 total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=7, min_samples_split=5;, score=0.948 total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=7, min_samples_split=5;, score=0.909 total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=7, min_samples_split=5;, score=0.926 total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=7, min_samples_split=5;, score=0.918 total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=7, min_samples_split=5;, score=0.905 total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=7, min_samples_split=7;, score=0.948 total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=7, min_samples_split=7;, score=0.909 total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=7, min_samples_split=7;, score=0.926 total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=7, min_samples_split=7;, score=0.918 total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=7, min_samples_split=7;, score=0.905 total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=8, min_samples_split=3;, score=0.983 total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=8, min_samples_split=3;, score=0.953 total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=8, min_samples_split=3;, score=0.961 total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=8, min_samples_split=3;, score=0.961 total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=8, min_samples_split=3;, score=0.952 total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=8, min_samples_split=5;, score=0.983 total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=8, min_samples_split=5;, score=0.953 total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=8, min_samples_split=5;, score=0.961 total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=8, min_samples_split=5;, score=0.961 total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=8, min_samples_split=5;, score=0.952 total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=8, min_samples_split=7;, score=0.983 total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=8, min_samples_split=7;, score=0.957 total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=8, min_samples_split=7;, score=0.948 total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=8, min_samples_split=7;, score=0.970 total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=8, min_samples_split=7;, score=0.939 total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=9, min_samples_split=3;, score=0.961 total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=9, min_samples_split=3;, score=0.953 total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=9, min_samples_split=3;, score=0.952 total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=9, min_samples_split=3;, score=0.970 total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=9, min_samples_split=3;, score=0.931 total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=9, min_samples_split=5;, score=0.953 total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=9, min_samples_split=5;, score=0.953 total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=9, min_samples_split=5;, score=0.948 total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=9, min_samples_split=5;, score=0.970 total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=9, min_samples_split=5;, score=0.935 total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=9, min_samples_split=7;, score=0.948 total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=9, min_samples_split=7;, score=0.957 total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=9, min_samples_split=7;, score=0.944 total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=9, min_samples_split=7;, score=0.957 total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=9, min_samples_split=7;, score=0.931 total time=   0.0s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-10 {color: black;background-color: white;}#sk-container-id-10 pre{padding: 0;}#sk-container-id-10 div.sk-toggleable {background-color: white;}#sk-container-id-10 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-10 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-10 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-10 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-10 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-10 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-10 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-10 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-10 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-10 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-10 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-10 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-10 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-10 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-10 div.sk-item {position: relative;z-index: 1;}#sk-container-id-10 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-10 div.sk-item::before, #sk-container-id-10 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-10 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-10 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-10 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-10 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-10 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-10 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-10 div.sk-label-container {text-align: center;}#sk-container-id-10 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-10 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-10\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=DecisionTreeClassifier(random_state=0),\n",
       "             param_grid={&#x27;criterion&#x27;: [&#x27;gini&#x27;, &#x27;entropy&#x27;],\n",
       "                         &#x27;max_depth&#x27;: [4, 5, 6, 7, 8, 9],\n",
       "                         &#x27;min_samples_split&#x27;: [3, 5, 7]},\n",
       "             scoring=&#x27;accuracy&#x27;, verbose=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-18\" type=\"checkbox\" ><label for=\"sk-estimator-id-18\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=DecisionTreeClassifier(random_state=0),\n",
       "             param_grid={&#x27;criterion&#x27;: [&#x27;gini&#x27;, &#x27;entropy&#x27;],\n",
       "                         &#x27;max_depth&#x27;: [4, 5, 6, 7, 8, 9],\n",
       "                         &#x27;min_samples_split&#x27;: [3, 5, 7]},\n",
       "             scoring=&#x27;accuracy&#x27;, verbose=3)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-19\" type=\"checkbox\" ><label for=\"sk-estimator-id-19\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(random_state=0)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-20\" type=\"checkbox\" ><label for=\"sk-estimator-id-20\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(random_state=0)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=DecisionTreeClassifier(random_state=0),\n",
       "             param_grid={'criterion': ['gini', 'entropy'],\n",
       "                         'max_depth': [4, 5, 6, 7, 8, 9],\n",
       "                         'min_samples_split': [3, 5, 7]},\n",
       "             scoring='accuracy', verbose=3)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "clf_en = DecisionTreeClassifier( random_state=0)\n",
    "clf = GridSearchCV(clf_en, tree_para,cv=5,scoring=\"accuracy\",verbose=3)\n",
    "clf.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-7 {color: black;background-color: white;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier(criterion=&#x27;entropy&#x27;, max_depth=8, min_samples_split=3,\n",
       "                       random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" checked><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(criterion=&#x27;entropy&#x27;, max_depth=8, min_samples_split=3,\n",
       "                       random_state=0)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier(criterion='entropy', max_depth=8, min_samples_split=3,\n",
       "                       random_state=0)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9619607404090162"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict the Test set results with criterion entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFittedError",
     "evalue": "This DecisionTreeClassifier instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [43]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m y_pred_en \u001b[38;5;241m=\u001b[39m \u001b[43mclf_en\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\tree\\_classes.py:504\u001b[0m, in \u001b[0;36mBaseDecisionTree.predict\u001b[1;34m(self, X, check_input)\u001b[0m\n\u001b[0;32m    481\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m    482\u001b[0m     \u001b[38;5;124;03m\"\"\"Predict class or regression value for X.\u001b[39;00m\n\u001b[0;32m    483\u001b[0m \n\u001b[0;32m    484\u001b[0m \u001b[38;5;124;03m    For a classification model, the predicted class for each sample in X is\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    502\u001b[0m \u001b[38;5;124;03m        The predicted classes, or the predict values.\u001b[39;00m\n\u001b[0;32m    503\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 504\u001b[0m     \u001b[43mcheck_is_fitted\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    505\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_X_predict(X, check_input)\n\u001b[0;32m    506\u001b[0m     proba \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtree_\u001b[38;5;241m.\u001b[39mpredict(X)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:1345\u001b[0m, in \u001b[0;36mcheck_is_fitted\u001b[1;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[0;32m   1340\u001b[0m     fitted \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m   1341\u001b[0m         v \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mvars\u001b[39m(estimator) \u001b[38;5;28;01mif\u001b[39;00m v\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m v\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1342\u001b[0m     ]\n\u001b[0;32m   1344\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m fitted:\n\u001b[1;32m-> 1345\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NotFittedError(msg \u001b[38;5;241m%\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mtype\u001b[39m(estimator)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m})\n",
      "\u001b[1;31mNotFittedError\u001b[0m: This DecisionTreeClassifier instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator."
     ]
    }
   ],
   "source": [
    "y_pred_en = clf_en.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check accuracy score with criterion entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_pred_en' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [44]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m accuracy_score\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mModel accuracy score with criterion entropy: \u001b[39m\u001b[38;5;132;01m{0:0.4f}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39m \u001b[38;5;28mformat\u001b[39m(accuracy_score(y_test, \u001b[43my_pred_en\u001b[49m)))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'y_pred_en' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print('Model accuracy score with criterion entropy: {0:0.4f}'. format(accuracy_score(y_test, y_pred_en)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare the train-set and test-set accuracy\n",
    "\n",
    "\n",
    "Now, I will compare the train-set and test-set accuracy to check for overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train_en = clf_en.predict(X_train)\n",
    "\n",
    "y_pred_train_en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Training-set accuracy score: {0:0.4f}'. format(accuracy_score(y_train, y_pred_train_en)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for overfitting and underfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the scores on training and test set\n",
    "\n",
    "print('Training set score: {:.4f}'.format(clf_en.score(X_train, y_train)))\n",
    "\n",
    "print('Test set score: {:.4f}'.format(clf_en.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the training-set score and test-set score is same as above. The training-set accuracy score is 0.7865 while the test-set accuracy to be 0.8021. These two values are quite comparable. So, there is no sign of overfitting. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize decision-trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'clf_en' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [37]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m12\u001b[39m,\u001b[38;5;241m8\u001b[39m))\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tree\n\u001b[1;32m----> 5\u001b[0m tree\u001b[38;5;241m.\u001b[39mplot_tree(\u001b[43mclf_en\u001b[49m\u001b[38;5;241m.\u001b[39mfit(X_train, y_train))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'clf_en' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 864x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "\n",
    "from sklearn import tree\n",
    "\n",
    "tree.plot_tree(clf_en.fit(X_train, y_train)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, based on the above analysis we can conclude that our classification model accuracy is very good. Our model is doing a very good job in terms of predicting the class labels.\n",
    "\n",
    "\n",
    "But, it does not give the underlying distribution of values. Also, it does not tell anything about the type of errors our classifer is making. \n",
    "\n",
    "\n",
    "We have another tool called `Confusion matrix` that comes to our rescue."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **15. Confusion matrix** <a class=\"anchor\" id=\"15\"></a>\n",
    "\n",
    "[Table of Contents](#0.1)\n",
    "\n",
    "\n",
    "A confusion matrix is a tool for summarizing the performance of a classification algorithm. A confusion matrix will give us a clear picture of classification model performance and the types of errors produced by the model. It gives us a summary of correct and incorrect predictions broken down by each category. The summary is represented in a tabular form.\n",
    "\n",
    "\n",
    "Four types of outcomes are possible while evaluating a classification model performance. These four outcomes are described below:-\n",
    "\n",
    "\n",
    "**True Positives (TP)** – True Positives occur when we predict an observation belongs to a certain class and the observation actually belongs to that class.\n",
    "\n",
    "\n",
    "**True Negatives (TN)** – True Negatives occur when we predict an observation does not belong to a certain class and the observation actually does not belong to that class.\n",
    "\n",
    "\n",
    "**False Positives (FP)** – False Positives occur when we predict an observation belongs to a    certain class but the observation actually does not belong to that class. This type of error is called **Type I error.**\n",
    "\n",
    "\n",
    "\n",
    "**False Negatives (FN)** – False Negatives occur when we predict an observation does not belong to a certain class but the observation actually belongs to that class. This is a very serious error and it is called **Type II error.**\n",
    "\n",
    "\n",
    "\n",
    "These four outcomes are summarized in a confusion matrix given below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the Confusion Matrix and slice it into four pieces\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred_en)\n",
    "\n",
    "print('Confusion matrix\\n\\n', cm)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **16. Classification Report** <a class=\"anchor\" id=\"16\"></a>\n",
    "\n",
    "[Table of Contents](#0.1)\n",
    "\n",
    "\n",
    "**Classification report** is another way to evaluate the classification model performance. It displays the  **precision**, **recall**, **f1** and **support** scores for the model. I have described these terms in later.\n",
    "\n",
    "We can print a classification report as follows:-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, y_pred_en))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **17. Results and conclusion** <a class=\"anchor\" id=\"17\"></a>\n",
    "\n",
    "[Table of Contents](#0.1)\n",
    "\n",
    "\n",
    "1.\tIn this project, I build a Decision-Tree Classifier model to predict the safety of the car. I build two models, one with criterion `gini index` and another one with criterion `entropy`. The model yields a very good performance as indicated by the model accuracy in both the cases which was found to be 0.8021.\n",
    "2.\tIn the model with criterion `gini index`, the training-set accuracy score is 0.7865 while the test-set accuracy to be 0.8021. These two values are quite comparable. So, there is no sign of overfitting.\n",
    "3.\tSimilarly, in the model with criterion `entropy`, the training-set accuracy score is 0.7865 while the test-set accuracy to be 0.8021.We get the same values as in the case with criterion `gini`. So, there is no sign of overfitting.\n",
    "4.\tIn both the cases, the training-set and test-set accuracy score is the same. It may happen because of small dataset.\n",
    "5.\tThe confusion matrix and classification report yields very good model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **18. References** <a class=\"anchor\" id=\"18\"></a>\n",
    "\n",
    "[Table of Contents](#0.1)\n",
    "\n",
    "\n",
    "The work done in this project is inspired from following books and websites:-\n",
    "\n",
    "1. Hands on Machine Learning with Scikit-Learn and Tensorflow by Aurélién Géron\n",
    "\n",
    "2. Introduction to Machine Learning with Python by Andreas C. Müller and Sarah Guido\n",
    "\n",
    "3. https://en.wikipedia.org/wiki/Decision_tree\n",
    "\n",
    "4. https://en.wikipedia.org/wiki/Information_gain_in_decision_trees\n",
    "\n",
    "5. https://en.wikipedia.org/wiki/Entropy_(information_theory)\n",
    "\n",
    "6. https://www.datacamp.com/community/tutorials/decision-tree-classification-python\n",
    "\n",
    "7. https://stackabuse.com/decision-trees-in-python-with-scikit-learn/\n",
    "\n",
    "8. https://acadgild.com/blog/decision-tree-python-code\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, now we will come to the end of this kernel.\n",
    "\n",
    "I hope you find this kernel useful and enjoyable.\n",
    "\t\n",
    "Your comments and feedback are most welcome.\n",
    "\n",
    "Thank you\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Go to Top](#0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
